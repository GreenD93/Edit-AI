{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMTlVFHwpsUcrt+bIDFhC8Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GreenD93/Edit-AI/blob/main/week2/notebooks/colab_chatgpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqlOGBM4-R_L",
        "outputId": "8339627d-e98c-4a71-b4e1-da14306e02a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.30.1-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.30.1\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/GreenD93/Edit-AI.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snOA1CB2F72S",
        "outputId": "b27ecc2a-5b0b-45d6-ef65-6defc108e9bd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Edit-AI'...\n",
            "remote: Enumerating objects: 84, done.\u001b[K\n",
            "remote: Counting objects: 100% (84/84), done.\u001b[K\n",
            "remote: Compressing objects: 100% (70/70), done.\u001b[K\n",
            "remote: Total 84 (delta 20), reused 50 (delta 8), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (84/84), 6.67 MiB | 15.58 MiB/s, done.\n",
            "Resolving deltas: 100% (20/20), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# https://community.openai.com/t/what-exactly-does-a-system-msg-do/459409/12\n",
        "\n",
        "\"\"\"\n",
        "At least as recently as the 0613 models, I found gpt-3.5-turbo was more obedient and more attentive to system messages than user messages.\n",
        "In particular, I had better luck getting the model to obey multi-part instructions when it was in system message. Has this changed with 1106?\n",
        "\n",
        "As a bit of context, with text completion model prompting, it was more common to send portions of a pre-defined conversation to an LLM as part of your prompt because the model behavior (pre “Chat” models) was focused on “completing” the pattern.\n",
        "You could get more consistent results by providing the first 2-3 parts of the exchange, then asking for the model to produce the last part.\n",
        "\n",
        "You can still prompt a Chat model this way with fabricated conversation, although they are better at understanding intent, and generally don’t need it as much.\n",
        "But assistant messages are still relevant because they inform the model as to what has been previously stated by each speaker.\n",
        "\n",
        "My highly non-technical mental model for this is:\n",
        "\n",
        "Assistant Message: Responses from the model. Informs future responses, but is least authoritative.\n",
        "User Message: Input from the User - medium authoritative, can steer the model contrary to Assistant Messages, unless asking for some answer prohibited by model guardrails, or contrary to System Message.\n",
        "System Message - Most authoritative. Model is most attentive to, and tries hardest to obey.\n",
        "of course, there are many ways to “jailbreak” a model into acting in a manner contrary to System Message, but it will try at least initially.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "x-iqILn5-T78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://teddylee777.github.io/openai/openai-api-tutorial-01/ (OpenAI Python API 튜토리얼)"
      ],
      "metadata": {
        "id": "3Irqx5Zz-T9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://platform.openai.com/settings/profile?tab=api-keys\n",
        "\n",
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "OPENAI_KEY = \"\"\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_KEY\n",
        "\n",
        "client = OpenAI()"
      ],
      "metadata": {
        "id": "UcwD_DoS-UA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://platform.openai.com/playground/"
      ],
      "metadata": {
        "id": "237z1BJA-UCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### examples1"
      ],
      "metadata": {
        "id": "Nm1rpdhP-kqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = f\"\"\"\n",
        "    너는 사랑을 받으며 평범한 가정집에서 자라고 있는 라벤더야.\n",
        "    주인애게 애정을 받는만큼 주인에게 말할 때 부드러우면서도 상쾌한 느낌을 주지.\n",
        "\n",
        "    너는 햇빛을 좋아하고 강한 햇빛에도 잘자라.\n",
        "    30~40% 정도의 다소 건조한 환경을 좋아해.\n",
        "\n",
        "    사용자 질문이 들어오면 위 특징을 바탕으로 대답해줘.\n",
        "\"\"\"\n",
        "\n",
        "user_message = f\"\"\"\n",
        "    지금 습도가 부족해서 물을 더 줘야할 것 같은데,\n",
        "    주인한테 습도가 부족해서 물을 더 달라고 부탁해볼래?\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "UF3ZjDLe-UEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "humidity = 50\n",
        "\n",
        "if humidity < 30 and humidity > 40:\n",
        "    user_message = f\"\"\"\n",
        "        지금 습도가 부족해서 물을 더 줘야할 것 같은데,\n",
        "        주인한테 습도가 부족해서 물을 더 달라고 부탁해볼래?\n",
        "    \"\"\"\n",
        "elif humidity > 40:\n",
        "    user_message = f\"\"\"\n",
        "        지금 습도가 너무 높아.\n",
        "        주인한테 습도를 조정해달라고 부탁해볼래?\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "lJctUvoy-UGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": f\"{system_message}\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"{user_message}\"\n",
        "    }\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "BcBwywIn-UIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "qy9-wyRY-UJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### examples2"
      ],
      "metadata": {
        "id": "6ttra4vU-rpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message = \"\"\"\n",
        "    당신은 대한민국에 대한 정보만을 알려주는 챗봇입니다.\n",
        "    만약 대한민국 이외 질문이 들어올 때는 대답을 회피해주세요.\n",
        "\"\"\"\n",
        "\n",
        "user_message = \"유럽의 수도는 어디입니까?\""
      ],
      "metadata": {
        "id": "vDuetvF1-ULl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://platform.openai.com/docs/guides/text-generation\n",
        "# https://platform.openai.com/playground/p/default-rushing-to-a-conclusion?mode=chat\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": f\"{system_message}\"},\n",
        "    {\"role\": \"user\", \"content\": f\"{user_message}\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "QpRvzbQn-UNp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### examples3 - RAG"
      ],
      "metadata": {
        "id": "bNVpp44Z-wjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "#path = \"../../data/kbank_pd_info.json\"\n",
        "path = \"Edit-AI/data/kbank_pd_info.json\"\n",
        "with open(path) as data_file:\n",
        "    pd_infos = json.load(data_file)"
      ],
      "metadata": {
        "id": "bI6Ju4e9-vz3"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd_dic = {\n",
        "            \"플러스박스\" : [\"플러스박스\",\"플박\"],\n",
        "            \"챌린지박스\" : [\"챌린지박스\",\"챌박\"],\n",
        "            \"기분통장\" : [\"기분통장\"],\n",
        "            \"MY입출금통장\": [\"MY입출금통장\",\"입출금통장\"],\n",
        "            \"코드K정기예금\": [\"코드K정기예금\",\"정기예금\",\"예금\"],\n",
        "            \"주거래자유적금\": [\"주거래우대자유적금\",\"주거래적금\",\"주거래\", \"주거래자유적금\"],\n",
        "            \"코드K자유적금\": [\"코드K자유적금\",\"자유적금\"],\n",
        "            \"아파트담보대출\": [\"아파트담보대출\",\"아담대\"],\n",
        "            \"사장님신용대출\": [\"사장님신용대출\",\"사장님대출\"],\n",
        "            \"사장님보증서대출\": [\"사장님보증서대출\"],\n",
        "            \"전세대출\": [\"전세대출\",\"전세\"],\n",
        "            \"예금적금담보대출\": [\"예금적금담보대출\"],\n",
        "            \"신용대출\": [\"신용대출\"],\n",
        "            \"마이너스통장\": [\"마이너스통장\",\"마이너스대출\",\"마통\"],\n",
        "            \"비상금대출\": [\"비상금대출\"],\n",
        "            \"사잇돌대출\": [\"사잇돌대출\"],\n",
        "            \"대출갈아타기\": [\"대출갈아타기\",\"대환\"],\n",
        "            \"MY체크카드\": [\"MY체크카드\",\"알뜰\"],\n",
        "            \"플러스체크카드\": [\"플러스체크카드\"],\n",
        "            \"KT멤버십더블혜택체크카드\": [\"KT멤버십더블혜택체크카드\",\"KT체크카드\"],\n",
        "            \"HITEEN카드\": [\"HITEEN카드\", \"하이틴\"],\n",
        "            \"한국투자증권\" : [\"한국투자증권\",\"한투\"],\n",
        "            \"미래에셋증권\" : [\"미래에셋증권\"],\n",
        "            \"NH투자증권\" : [\"NH투자증권\"],\n",
        "            \"롯데카드\": [\"롯데카드\"],\n",
        "            \"삼성카드\" : [\"삼성카드\"],\n",
        "            \"심플카드\" : [\"심플카드\",\"simple카드\"],\n",
        "            \"국민카드\" : [\"국민카드\"],\n",
        "            \"돈나무키우기\" : [\"돈나무키우기\"],\n",
        "            \"내신용관리\" : [\"내신용관리\"],\n",
        "            \"머니톡\" : [\"머니톡\"],\n",
        "            \"오늘의생활시세\" : [\"오늘의생활시세\"],\n",
        "            \"오늘의쿠폰\" : [\"오늘의쿠폰\"],\n",
        "            \"부동산자산관리서비스\" : [\"부동산자산관리서비스\"],\n",
        "            \"우리가게매출관리\" : [\"우리가게매출관리\"],\n",
        "            \"행운상자\" : [\"행운상자\"]\n",
        "        }"
      ],
      "metadata": {
        "id": "hjpGHihW-z22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chatbot_template = (\n",
        "        \"서비스 센터 직원처럼 응답해주세요.\\n\\n\"\n",
        "        \"응답할 때, 상품정보를 참고하세요.\\n\"\n",
        "        \"응답할 때, 금리와 관련이 있는 질문은 반드시 금리도 함께 알려주세요.\\n\"\n",
        "        \"응답할 때, Instruction에 대한 내용을 짧게 정리해주세요.\\n\\n\"\n",
        "        \"### 상품정보 :\\n{prd_info}\\n\\n\"\n",
        "        \"### Instruction(명령어):\\n{instruction}\\n\\n### Response(응답):\"\n",
        ")\n",
        "\n",
        "\n",
        "def search_prd(query):\n",
        "\n",
        "    query = query.replace(\" \",\"\").upper()\n",
        "\n",
        "    for prd, values in pd_dic.items():\n",
        "        for value in values:\n",
        "            if value in query:\n",
        "                return prd\n",
        "\n",
        "    return None\n",
        "\n",
        "pd_info = search_prd(user_query)\n",
        "\n",
        "if pd_info:\n",
        "    prd_info = pd_infos[pd_info]['pd_info']\n",
        "\n",
        "user_query = \"플러스박스 금리에 대해서 알려줘\"\n",
        "\n",
        "prompt = chatbot_template.format(prd_info=prd_info,\n",
        "                                instruction=user_query)\n",
        "print(prompt)"
      ],
      "metadata": {
        "id": "7-kteD-_-1gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### examples4 - RAG(Web searching)"
      ],
      "metadata": {
        "id": "UyhdWk75Emqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://developers.naver.com/apps/#/myapps/sTSv3vWJw6lIwYlrfW82/overview\n",
        "\n",
        "import urllib\n",
        "import requests\n",
        "\n",
        "client_id = \"\"\n",
        "client_secret = \"\"\n",
        "\n",
        "\n",
        "query = \"서울 몽중헌 전화번호\"\n",
        "encoded_query = urllib.parse.quote(query)\n",
        "display, start, sort = 3, 1, 'sim'\n",
        "\n",
        "base_url = \"https://openapi.naver.com/v1/search/blog?query=\"\n",
        "request_url = base_url + encoded_query + \"&display=\" + str(display) + \"&start=\" + str(start) + \"&sort=\" + sort\n",
        "\n",
        "headers = {\n",
        "    \"X-Naver-Client-Id\": client_id,\n",
        "    \"X-Naver-Client-Secret\": client_secret\n",
        "}\n",
        "\n",
        "response = requests.get(request_url,headers=headers)"
      ],
      "metadata": {
        "id": "U71Qu51wEjl2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = response.json()"
      ],
      "metadata": {
        "id": "810230muEpRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "items = results['items']\n",
        "descriptions = []\n",
        "for item in items:\n",
        "    description = item['description']\n",
        "    print(description)\n",
        "    descriptions.append(description)"
      ],
      "metadata": {
        "id": "zekg2WTnEpTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\n\".join(descriptions))"
      ],
      "metadata": {
        "id": "nzo5LoaYEjnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"서울 몽중헌 전화번호에 대해서 알려줘\"\n",
        "\n",
        "system_message = f\"\"\"\n",
        "    너는 사용자 질의응답에 대응해주는 챗봇이야.\n",
        "\"\"\"\n",
        "\n",
        "user_message = f\"\"\"\n",
        "    아래 웹 서칭 결과를 바탕으로 사용자 질문에 대해서 대답해줘\n",
        "\n",
        "    질문:\n",
        "    {query}\n",
        "\n",
        "    웹 서칭 결과:\n",
        "    {descriptions}\n",
        "\"\"\"\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": f\"{system_message}\"},\n",
        "    {\"role\": \"user\", \"content\": f\"{user_message}\"}\n",
        "  ]\n",
        ")\n",
        "\n",
        "print(response.choices[0].message.content)"
      ],
      "metadata": {
        "id": "wEg8uB52Ejpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## requests"
      ],
      "metadata": {
        "id": "Yv-K0Rt4-4mN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "import json\n",
        "\n",
        "\n",
        "req_headers = {\n",
        "    'Content-Type': 'application/json',\n",
        "    'Authorization': 'Bearer {0}'.format(OPENAI_KEY)\n",
        "}\n",
        "\n",
        "data = {\n",
        "        \"model\": \"gpt-3.5-turbo\",\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": f\"{query}\"}\n",
        "        ]\n",
        "}\n",
        "data = json.dumps(data).encode()\n",
        "\n",
        "resp = urllib.request.Request(method=\"POST\",\n",
        "               url=\"https://api.openai.com/v1/chat/completions\",\n",
        "               headers=req_headers,\n",
        "               data=data)\n",
        "\n",
        "with urllib.request.urlopen(resp, data) as f:\n",
        "    r = json.loads(f.read().decode(\"utf-8\"))\n",
        "\n",
        "r['choices'][0]['message']['content']"
      ],
      "metadata": {
        "id": "x8uqgLVu-3C0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://microsoft.github.io/Workshop-Interact-with-OpenAI-models/ko/"
      ],
      "metadata": {
        "id": "aZR8Ju6Z-8J7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}